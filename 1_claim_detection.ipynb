{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim detection\n",
    "The dataset(IBM Debator - Claim Stance Dataset) can be accessed [here](http://www.research.ibm.com/haifa/dept/vst/debating_data.shtml)\n",
    "\n",
    "This dataset contains: 2,394 labeled claims for 55 topics. The dataset includes the stance (Pro/Con) of each claim towards the topic, as well as fine-grained annotations, based on the semantic model of Bar-Haim et al. [2017a] (topic target, topic sentiment towards its target, claim target, claim sentiment towards its target, and the relation \n",
    "between the targets).\n",
    "\n",
    "The dataset includes: \n",
    "1. A utf-8 JSON file containing the topics and the claims found for these topics in Wikipedia articles. \n",
    "   Topics and claims are annotated as described above. \n",
    "2. A utf-8 CSV file containing the same information as the JSON file.\n",
    "3. The original Wikipedia articles - from Wikipedia April 2012 dump - in the form of text files. \n",
    "   For each article, we provide both the original (raw) version, and a clean version, in which any Wikisyntax \n",
    "   and HTML markup is removed.\n",
    "4. A CSV index file, containing the article title and Wikipedia URL for each article.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "root = os.getcwd() + '/IBM_EACL-2017.v1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading in data\n",
    "\n",
    "### articles\n",
    "num: 547\n",
    "\n",
    "Note: There're 5013 texts within articles folder, so this dataframe only contains articles that are labeled as one of the 58 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        text = f.read().split('\\n')\n",
    "        for parag in text:\n",
    "            if len(parag) >2:\n",
    "                data = data + [a for a in parag.split('. ') if len(a)>0]\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles = dict()\n",
    "for subdir, dirs, files in os.walk(root+'articles/'):\n",
    "    for file in files:\n",
    "        if file[-3:] == 'txt' and file[:5] == 'clean':\n",
    "            filename = os.path.join(subdir, file)\n",
    "            articles[file] = read_file(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Controversies over video games often center on topics such as video game graphic violence, sex and sexism, violent and gory scenes, partial or full nudity, portrayal of criminal behavior, racism, and other provocative and objectionable material',\n",
       " 'Video games have been studied for links to addiction and aggression']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['clean_1.txt'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_paths = set(claimDF['claims.article.cleanFile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### claims\n",
    "num: 2394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "claimDF = pd.read_csv(\"IBM_EACL-2017.v1/claim_stance_dataset_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topicId</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topicText</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topicTarget</th>\n",
       "      <td>the sale of violent video games to minors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topicSentiment</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimId</th>\n",
       "      <td>2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.stance</th>\n",
       "      <td>PRO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimCorrectedText</th>\n",
       "      <td>Exposure to violent video games causes at leas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimOriginalText</th>\n",
       "      <td>exposure to violent video games causes at leas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.article.rawFile</th>\n",
       "      <td>articles/t1/raw_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.article.rawSpan.start</th>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.article.rawSpan.end</th>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.article.cleanFile</th>\n",
       "      <td>articles/t1/clean_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.article.cleanSpan.start</th>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.article.cleanSpan.end</th>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.Compatible</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimTarget.text</th>\n",
       "      <td>Exposure to violent video games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimTarget.span.start</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimTarget.span.end</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.claimSentiment</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claims.targetsRelation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                0\n",
       "topicId                                                                         1\n",
       "split                                                                        test\n",
       "topicText                       This house believes that the sale of violent v...\n",
       "topicTarget                             the sale of violent video games to minors\n",
       "topicSentiment                                                                 -1\n",
       "claims.claimId                                                               2973\n",
       "claims.stance                                                                 PRO\n",
       "claims.claimCorrectedText       Exposure to violent video games causes at leas...\n",
       "claims.claimOriginalText        exposure to violent video games causes at leas...\n",
       "claims.article.rawFile                                      articles/t1/raw_1.txt\n",
       "claims.article.rawSpan.start                                                  490\n",
       "claims.article.rawSpan.end                                                    640\n",
       "claims.article.cleanFile                                  articles/t1/clean_1.txt\n",
       "claims.article.cleanSpan.start                                                418\n",
       "claims.article.cleanSpan.end                                                  568\n",
       "claims.Compatible                                                             yes\n",
       "claims.claimTarget.text                           Exposure to violent video games\n",
       "claims.claimTarget.span.start                                                   0\n",
       "claims.claimTarget.span.end                                                    31\n",
       "claims.claimSentiment                                                          -1\n",
       "claims.targetsRelation                                                          1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claimDF[:1].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I've just realized that one sentence could contain more than one claims, \n",
    "# so I'll just tag it as 1 as long as it contains one claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles_tags = []\n",
    "articles_sent_length = []\n",
    "sentences = []\n",
    "topics = []\n",
    "article_locs = []\n",
    "\n",
    "for a in article_paths:\n",
    "    article_name = a.split('/')[-1]\n",
    "    sents = articles[article_name]\n",
    "    claims = list(claimDF[claimDF['claims.article.cleanFile'] == a]['claims.claimOriginalText'])\n",
    "    topic = list(claimDF[claimDF['claims.article.cleanFile'] == a]['topicTarget'])[0]\n",
    "    tags = []\n",
    "    sent_length = []\n",
    "    locs = []\n",
    "\n",
    "    for i, sent in enumerate(sents):\n",
    "        locs.append(i)\n",
    "        # get sent length\n",
    "        tokens = [a for a in sent.split() if a != '']\n",
    "        sent_length.append(len(tokens))\n",
    "        topics.append(topic)\n",
    "        flag = False\n",
    "        for claim in claims:\n",
    "            if claim in sent:\n",
    "                tags.append(1)\n",
    "                claims.remove(claim)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            tags.append(0)  \n",
    "    \n",
    "    sentences.append(sents)\n",
    "    articles_tags.append(tags)\n",
    "    article_locs.append(locs)\n",
    "    articles_sent_length.append(sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'sentences': sum(sentences, []), \n",
    "     'topic': topics, \n",
    "     'length': sum(articles_sent_length, []), \n",
    "     'label': sum(articles_tags, []),\n",
    "    'loc': sum(article_locs, [])}\n",
    "tmp = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list(zip(sum(sentences, []), topics,\\\n",
    "           sum(articles_sent_length, []), sum(articles_tags, []), sum(article_locs, [])))\n",
    "\n",
    "# sentence, topic, length, label, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Brown v', 'the sale of violent video games to minors', 2, 0, 0)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2.  Feature Engineeing\n",
    "\n",
    "- Mean embedding of the sentence\n",
    "- similarity between sentence and topic (cosine similarity )\n",
    "- length of the sentence\n",
    "- index of the sentence in the article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore codes starting from here\n",
    "## Organizing data into ready-to-train format\n",
    "\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    return x.lower().strip(' ').translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_text(x):\n",
    "    t = ''\n",
    "    filename = \"CE-EMNLP-2015.V3/articles/clean_\"+str(x)+\".txt\"\n",
    "    for line in open(filename, 'r'):\n",
    "        t += line\n",
    "    return t\n",
    "\n",
    "def find_claim(x, dic):\n",
    "    # finding claims from dictionary{article id: [claims]}\n",
    "    try:\n",
    "        return dic[x]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean up claimDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "claimDF['original_rmv_punc'] = claimDF['Claim original text'].apply(lambda x: clean(x))\n",
    "#claimDF['Claim corrected version'] = claimDF['Claim corrected version'].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topicId</th>\n",
       "      <th>split</th>\n",
       "      <th>topicText</th>\n",
       "      <th>topicTarget</th>\n",
       "      <th>topicSentiment</th>\n",
       "      <th>claims.claimId</th>\n",
       "      <th>claims.stance</th>\n",
       "      <th>claims.claimCorrectedText</th>\n",
       "      <th>claims.claimOriginalText</th>\n",
       "      <th>claims.article.rawFile</th>\n",
       "      <th>...</th>\n",
       "      <th>claims.article.rawSpan.end</th>\n",
       "      <th>claims.article.cleanFile</th>\n",
       "      <th>claims.article.cleanSpan.start</th>\n",
       "      <th>claims.article.cleanSpan.end</th>\n",
       "      <th>claims.Compatible</th>\n",
       "      <th>claims.claimTarget.text</th>\n",
       "      <th>claims.claimTarget.span.start</th>\n",
       "      <th>claims.claimTarget.span.end</th>\n",
       "      <th>claims.claimSentiment</th>\n",
       "      <th>claims.targetsRelation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>the sale of violent video games to minors</td>\n",
       "      <td>-1</td>\n",
       "      <td>2973</td>\n",
       "      <td>PRO</td>\n",
       "      <td>Exposure to violent video games causes at leas...</td>\n",
       "      <td>exposure to violent video games causes at leas...</td>\n",
       "      <td>articles/t1/raw_1.txt</td>\n",
       "      <td>...</td>\n",
       "      <td>640</td>\n",
       "      <td>articles/t1/clean_1.txt</td>\n",
       "      <td>418</td>\n",
       "      <td>568</td>\n",
       "      <td>yes</td>\n",
       "      <td>Exposure to violent video games</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>the sale of violent video games to minors</td>\n",
       "      <td>-1</td>\n",
       "      <td>2974</td>\n",
       "      <td>CON</td>\n",
       "      <td>video game violence is not related to serious ...</td>\n",
       "      <td>video game violence is not related to serious ...</td>\n",
       "      <td>articles/t1/raw_1.txt</td>\n",
       "      <td>...</td>\n",
       "      <td>1697</td>\n",
       "      <td>articles/t1/clean_1.txt</td>\n",
       "      <td>829</td>\n",
       "      <td>907</td>\n",
       "      <td>yes</td>\n",
       "      <td>video game violence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   topicId split                                          topicText  \\\n",
       "0        1  test  This house believes that the sale of violent v...   \n",
       "1        1  test  This house believes that the sale of violent v...   \n",
       "\n",
       "                                 topicTarget  topicSentiment  claims.claimId  \\\n",
       "0  the sale of violent video games to minors              -1            2973   \n",
       "1  the sale of violent video games to minors              -1            2974   \n",
       "\n",
       "  claims.stance                          claims.claimCorrectedText  \\\n",
       "0           PRO  Exposure to violent video games causes at leas...   \n",
       "1           CON  video game violence is not related to serious ...   \n",
       "\n",
       "                            claims.claimOriginalText claims.article.rawFile  \\\n",
       "0  exposure to violent video games causes at leas...  articles/t1/raw_1.txt   \n",
       "1  video game violence is not related to serious ...  articles/t1/raw_1.txt   \n",
       "\n",
       "            ...            claims.article.rawSpan.end  \\\n",
       "0           ...                                   640   \n",
       "1           ...                                  1697   \n",
       "\n",
       "   claims.article.cleanFile claims.article.cleanSpan.start  \\\n",
       "0   articles/t1/clean_1.txt                            418   \n",
       "1   articles/t1/clean_1.txt                            829   \n",
       "\n",
       "   claims.article.cleanSpan.end  claims.Compatible  \\\n",
       "0                           568                yes   \n",
       "1                           907                yes   \n",
       "\n",
       "           claims.claimTarget.text claims.claimTarget.span.start  \\\n",
       "0  Exposure to violent video games                           0.0   \n",
       "1              video game violence                           0.0   \n",
       "\n",
       "   claims.claimTarget.span.end  claims.claimSentiment  claims.targetsRelation  \n",
       "0                         31.0                   -1.0                     1.0  \n",
       "1                         19.0                    1.0                     1.0  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claimDF[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get original text of these articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "artDF['text'] = artDF['article Id'].apply(lambda x: read_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Title</th>\n",
       "      <th>article Id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>Video game content rating system</td>\n",
       "      <td>567</td>\n",
       "      <td>A video game content rating system is a system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>Grand Theft Childhood</td>\n",
       "      <td>524</td>\n",
       "      <td>Grand Theft Childhood: The Surprising Truth Ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>School violence</td>\n",
       "      <td>542</td>\n",
       "      <td>School violence is widely held to have become ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>Video game controversies</td>\n",
       "      <td>1</td>\n",
       "      <td>. \\n\\nControversies over video games often cen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  This house believes that the sale of violent v...   \n",
       "1  This house believes that the sale of violent v...   \n",
       "2  This house believes that the sale of violent v...   \n",
       "3  This house believes that the sale of violent v...   \n",
       "\n",
       "                              Title  article Id  \\\n",
       "0  Video game content rating system         567   \n",
       "1             Grand Theft Childhood         524   \n",
       "2                   School violence         542   \n",
       "3          Video game controversies           1   \n",
       "\n",
       "                                                text  \n",
       "0  A video game content rating system is a system...  \n",
       "1  Grand Theft Childhood: The Surprising Truth Ab...  \n",
       "2  School violence is widely held to have become ...  \n",
       "3  . \\n\\nControversies over video games often cen...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artDF[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each article, find the extracted claimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic                      This house believes that the sale of violent v...\n",
       "Claim original text        Exposure to violent video games causes at leas...\n",
       "Claim corrected version    exposure to violent video games causes at leas...\n",
       "original_rmv_punc          exposure to violent video games causes at leas...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#claimDF.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "notFound = []\n",
    "for i in range(len(claimDF)):\n",
    "    topic = claimDF.iloc[i,0]\n",
    "    claim = str(claimDF.iloc[i,3])\n",
    "    df = artDF[artDF['Topic']==topic]\n",
    "    flag = False\n",
    "    for j in range(len(df)):\n",
    "        if claim in df.iloc[j,3]:\n",
    "            flag = True\n",
    "            try:\n",
    "                dic[df.iloc[j,2]].append(claim)\n",
    "            except:\n",
    "                dic[df.iloc[j,2]] = [claim]\n",
    "    if flag == False:\n",
    "        notFound.append((i, topic, claim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artDF['claims'] = artDF['article Id'].apply(lambda x: find_claim(x,dic))\n",
    "\n",
    "artDF['num_claim'] = artDF['claims'].apply(lambda x: len(x))\n",
    "\n",
    "artDF['num_claim'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1634"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(notFound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artDF['sentences'] = artDF['text'].apply(lambda x: [clean(sent) for sent in x.split('.')])\n",
    "artDF['num_sents'] = artDF['sentences'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Title</th>\n",
       "      <th>article Id</th>\n",
       "      <th>text</th>\n",
       "      <th>claims</th>\n",
       "      <th>num_claim</th>\n",
       "      <th>sentences</th>\n",
       "      <th>num_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>Video game content rating system</td>\n",
       "      <td>567</td>\n",
       "      <td>A video game content rating system is a system...</td>\n",
       "      <td>[numerous researchers have proposed potential ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a video game content rating system is a syste...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>Grand Theft Childhood</td>\n",
       "      <td>524</td>\n",
       "      <td>Grand Theft Childhood: The Surprising Truth Ab...</td>\n",
       "      <td>[most children who play violent games do not h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[grand theft childhood the surprising truth ab...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>School violence</td>\n",
       "      <td>542</td>\n",
       "      <td>School violence is widely held to have become ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[school violence is widely held to have become...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This house believes that the sale of violent v...</td>\n",
       "      <td>Video game controversies</td>\n",
       "      <td>1</td>\n",
       "      <td>. \\n\\nControversies over video games often cen...</td>\n",
       "      <td>[video game violence is not related to serious...</td>\n",
       "      <td>10</td>\n",
       "      <td>[, \\n\\ncontroversies over video games often ce...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  This house believes that the sale of violent v...   \n",
       "1  This house believes that the sale of violent v...   \n",
       "2  This house believes that the sale of violent v...   \n",
       "3  This house believes that the sale of violent v...   \n",
       "\n",
       "                              Title  article Id  \\\n",
       "0  Video game content rating system         567   \n",
       "1             Grand Theft Childhood         524   \n",
       "2                   School violence         542   \n",
       "3          Video game controversies           1   \n",
       "\n",
       "                                                text  \\\n",
       "0  A video game content rating system is a system...   \n",
       "1  Grand Theft Childhood: The Surprising Truth Ab...   \n",
       "2  School violence is widely held to have become ...   \n",
       "3  . \\n\\nControversies over video games often cen...   \n",
       "\n",
       "                                              claims  num_claim  \\\n",
       "0  [numerous researchers have proposed potential ...          1   \n",
       "1  [most children who play violent games do not h...          1   \n",
       "2                                                 []          0   \n",
       "3  [video game violence is not related to serious...         10   \n",
       "\n",
       "                                           sentences  num_sents  \n",
       "0  [a video game content rating system is a syste...        107  \n",
       "1  [grand theft childhood the surprising truth ab...         60  \n",
       "2  [school violence is widely held to have become...        136  \n",
       "3  [, \\n\\ncontroversies over video games often ce...        299  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artDF[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#artDF['claims'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#artDF['sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-06db512e1137>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-06db512e1137>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if x\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# def determine_label(x):\n",
    "#      if x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(artDF)):\n",
    "    sents = artDF['sentences'][i]\n",
    "    claims = artDF['claims'][i]\n",
    "    label = []\n",
    "    for sent in sents:\n",
    "        flag = False\n",
    "        for claim in claims:\n",
    "            if claim in clean(sent):\n",
    "                label.append(1)\n",
    "                flag = True\n",
    "                break\n",
    "        if flag == False:\n",
    "            label.append(0)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artDF['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(artDF['label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artDF['sum_label'] = artDF['label'].apply(lambda x: sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(artDF['sum_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: I keep losing claims!!\n",
    "\n",
    "## What if I don't keep track of the article that the sentences are in, and just determine them altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = ''\n",
    "for i in artDF['text']:\n",
    "    all_text += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sents = all_text.split('. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "claims = claimDF['original_rmv_punc']\n",
    "labels = []\n",
    "for sent in all_sents:\n",
    "    sent = clean(sent)\n",
    "    flag = False\n",
    "    for claim in claims:\n",
    "        if claim in sent:\n",
    "            labels.append(1)\n",
    "            flag = True\n",
    "            break\n",
    "    if flag == False:\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75675"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75675"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major problem: when there suppose to be 2294 claims, I'm only able to find 1702 sentences that contain claims using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'Sent': all_sents, 'Contains_claims': labels}\n",
    "sentDF = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contains_claims</th>\n",
       "      <th>Sent</th>\n",
       "      <th>?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A video game content rating system is a system...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Most of these systems are associated with and/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The utility of such ratings has been called in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Video game content rating systems can be used ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Rating checking and approval is part of the ga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contains_claims                                               Sent  ?\n",
       "0                0  A video game content rating system is a system...  0\n",
       "1                0  Most of these systems are associated with and/...  0\n",
       "2                0  The utility of such ratings has been called in...  0\n",
       "3                0  Video game content rating systems can be used ...  0\n",
       "4                0  Rating checking and approval is part of the ga...  0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentDF[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction\n",
    "1. ？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qMark(x):\n",
    "    try:\n",
    "        if x[-1] == '?':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentDF['?'] = sentDF['Sent'].apply(lambda x: qMark(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Belief words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text rank/text summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sumy\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.parsers.html import HtmlParser\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "#from sumy.summarizers.lsa import LsaSummarizer as Summarizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "#from sumy.utils import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = artDF['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numerous researchers have proposed potential positive effects of video games']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artDF['claims'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SENTENCES_COUNT = artDF['num_sents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-21493e1ccc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# summarizer.stop_words = get_stop_words(LANGUAGE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSENTENCES_COUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sumy/summarizers/text_rank.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, document, sentences_count)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_best_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrate_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sumy/summarizers/_summarizer.py\u001b[0m in \u001b[0;36m_get_best_sentences\u001b[0;34m(self, sentences, count, rating, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# sort sentences by their order in document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"order\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "LANGUAGE = 'English'\n",
    "parser = PlaintextParser.from_string(t, Tokenizer('English'))\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "summarizer.stop_words = nltk.corpus.stopwords.words('english')\n",
    "# summarizer = Summarizer(stemmer)\n",
    "# summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "for sentence in summarizer(parser.document, SENTENCES_COUNT):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw textrank\n",
    "https://joshbohde.com/blog/document-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    " \n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    " \n",
    "def textrank(document):\n",
    "    sentence_tokenizer = PunktSentenceTokenizer()\n",
    "    sentences = sentence_tokenizer.tokenize(document)\n",
    " \n",
    "    bow_matrix = CountVectorizer().fit_transform(sentences)\n",
    "    normalized = TfidfTransformer().fit_transform(bow_matrix)\n",
    " \n",
    "    similarity_graph = normalized * normalized.T\n",
    " \n",
    "    nx_graph = nx.from_scipy_sparse_matrix(similarity_graph)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    return sorted(((scores[i],s) for i,s in enumerate(sentences)),\n",
    "                  reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.018228815830554752,\n",
       "  'The (CERO) is the organization that rates video games and PC games (except dating sim, visual novel, and eroge) in Japan with levels of rating that informs the customer of the nature of the product and for what age group it is suitable.'),\n",
       " (0.015257808196775656,\n",
       "  'It is responsible for inspecting and rating the content of films and interactive games.'),\n",
       " (0.014390936223200246,\n",
       "  'A video game content rating system is a system used for the classification of video games into suitability-related groups.'),\n",
       " (0.014305087014280488,\n",
       "  'In July 1994, the IDSA (renamed to the Entertainment Software Association in 2003) presented to Congress its proposal for an industry-controlled rating system; in September of that same year, the Entertainment Software Rating Board (ESRB) was unveiled.'),\n",
       " (0.014081788072994273,\n",
       "  'Video game content rating systems can be used as the basis for laws that cover the sales of video games to minors, such as in Australia.'),\n",
       " (0.013834695509275215,\n",
       "  'The Entertainment Software Rating Board (ESRB) is a self-regulatory organization that assigns age and content ratings, enforces industry-adopted advertising guidelines, and ensures responsible online privacy principles for computer and video games and other entertainment software in Canada and the United States [REF].'),\n",
       " (0.013710836805204929,\n",
       "  'The Office of Film and Literature Classification (OFLC, ) is the government agency in New Zealand that is responsible for classification of all films, videos, publications, and some video games in New Zealand.'),\n",
       " (0.013636054518674647,\n",
       "  'PEGI self-regulation is composed by five age categories and eight content descriptors that advise the suitability and content of a game for a certain age range based on the games content [REF].'),\n",
       " (0.013017418468808875,\n",
       "  'The big dog in the fight was the result of the April 1994 formation of the Interactive Digital Software Association (IDSA), a trade group assembled from the most powerful game developers and publishers in the country.'),\n",
       " (0.012669252039261336,\n",
       "  'A governmental organization, the GRB rates video and computer games to inform customers of the nature of game contents.')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank(t)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = 'Silicon Valley has looked into the future and seen what many of us are seeing – automation and technology are replacing jobs faster than businesses are creating them. What started as a mere murmurings has reverberated louder into an open call from some of the wealthiest businesspeople in the United States including Mark Zuckerberg and Elon Musk for universal basic income.Universal basic income is a stipend paid by the government to individuals simply for being alive. The idea began in Europe and has been gaining momentum in several countries. The principal behind the idea is that it serves as a safety net for unemployment due to market forces such as automation. Several countries have begun experimenting with a basic income including an experiment run in Ontario, Canada, which distributed a stipend of $12, 616 as its basic income. The idea has started to gain traction in America.Hawaii recently became the first state to make a major push towards a universal basic income. As of this May, the Hawaii state legislature adopted HCR 89 calling for the Department of Labor and Industrial Relations and the Department of Business, Economic Development, and Tourism to convene a basic income economic security working group to begin to structure a universal basic income. The relevant text from the resolution gives the group’s focus:WHEREAS, while the United States is the wealthiest nation in the world, many families, individuals, and businesses in Hawaii have been struggling to keep pace with the increasing cost of living as economic inequality widens the gap between a few top earners and the middle and lower class, the latter of which has seen its overall share of income decline in recent decades; and WHEREAS, efforts to increase wages, benefits, and working conditions are important steps to assist local families in the short-term, but a paradigm shift in policy will soon be necessary as automation, innovation, and disruption begin to rapidly worsen economic inequality by displacing significant numbers of jobs in Hawaii’s transportation, food service, tourism, retail, medical, legal, insurance, and other sectors …Hawaii state representative Chris Lee led the push towards a basic income and predicted that Hawaii’s future economic troubles due to Silicon Valley innovations like self-driving cars and Airbnb to be potentially hazardous to Hawaii’s tourist-dependent economy. Though this seems to be an anticipatory measure, however; as of April 2017, Hawaii’s unemployment rate was at a ten year low. This fact didn’t stop the Democrat dominated state legislature from approving the measure.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1 += \"In other parts of the country, calls in for universal basic income are growing. In California, Silicon Valley has made well known their support for a basic income citing the necessity of social security from the jobs they will take away with their businesses. In the media, a cursory search of liberal publications reveals a bolder comfort with an idea of providing a stipend to people for doing nothing. In Georgia, former documentary assistant turned congressional candidate, Jon Ossoff, went above and beyond agreeing to a $15 minimum wage and instead gave a nod to his California benefactors by saying he would push for a “living wage” in the final debate for the Georgia Sixth Congressional district special election. It’s easy to see the sly rhetorical distinction between “living wage” and “basic income.”There is very little hope that this trend will change without forward-thinking leaders who will refuse to rest on lazy ideas like the universal basic income.Our politicians have been able to see technology replacing jobs for decades now and made little adjustments other than to make more individuals reliant on the government for their economic well being. I echo what I wrote in The Hill last September that automation would require lawmakers to be innovative in their approaches for creating jobs. Many lawmakers and those in the best position to see automation replacing jobs, such as CEO’s in Silicon Valley, it would appear are opting towards a more top-down income redistribution in the form of a universal basic income rather than wrestle with retraining workers, re-calibrating the economy, or encouraging innovation to offset job loss.This is to simply say: universal basic income is a lazy, socialist solution to future unemployment problems. There are dozens of issues with universal basic income, but I will list some of the bigger issues below. As to avoid being an armchair critic who only points out mistakes, I will also offer up some of my own solutions or alternatives to reposition our economy.First, universal basic income stifles economic growth through exorbitant tax rates. To pay for a basic income that would be a living income or sustainable income requires taxation of wage earners well above 50% for the highest and second highest tax brackets. Offsetting high cost of living cities like New York, San Francisco, and Washington, D.C. would necessitate a tax rate unsustainable for most Americans. This leads to either a subsidy for poor Americans, or force many low-income individuals to relocate out of major cities. Needless to say, this exodus hampers innovation.With our current immigration debate, this analysis presumes a comparable rate of illegal immigration and immigration as we have seen in recent years. If history is any indication, the moment a universal basic income comes into law for U.S. citizens, Mayor de Blasio and Governor Cuomo will rush to the front of public debate to argue that universal basic income should be extended to undocumented workers as well since it’s a human right. If that happens, keep your wallets open because that’s going to hurt.Second, universal basic income is a mere proxy for socialism. The plan relies on the assumption that the income will be a social safety net to hedge against unemployment. In a perfect world, individuals would be able to save to offset economic unpredictability. This is an interesting argument to hear coming from a Left who finds the thought of alternatives to social security and Obamacare in the form of private savings account abhorrent. If liberals don’t trust Americans to allocate their money correctly, how can they reasonably suspect that this universal income will be treated differently to realistically serve as a safety net?Finally, a basic universal income only hedges against future unemployment rather than creating opportunities in the present to anticipate economic changes. If automation continues to replace jobs, more Americans will shift from universal basic income being a subsidy to their earned wages towards it being a necessity in unemployment. It’s easy to see how this would spiral the economy into the garbage heap. As workers exit the workforce, fewer workers pay into the pool for distribution meaning that there is less money for the same amount of government handouts. To accommodate the gap, either taxes would have to go up on higher income earners to account for a depleting workforce, or businesses and the government would have to create alternatives to get people to work, or the government would have to require businesses to hire individuals. (Beginning to sound a bit like Atlas Shrugged.) All are bad alternatives. Creating a safety net that promises no ability to put people to work is giving them $1,000, not teaching them to build boats or sail, and asking them to get off an island.There is still time to right the ship. As I said at the outset, nay saying without a solution is as empty as the politicians that will inevitably thrust the universal basic income upon us. There are many avenues to avoiding the calamity from unemployment Silicon Valley predicts from their innovation. I will list several here.First, public schools and innovative STEM charter schools need the resources to teach STEM subjects and trade skills. Understanding how the workforce is being educated and what they are learning are far too often overlooked. For one, a realistic alternative would be to increase trade skills education during high school education while it is cheaper in order to provide career paths for students that do not seek a college degree while equipping them with a skill. It will be a long time before a plumber or electrician can be replaced by a machine. Access to STEM early in education will also improve female participation in STEM fields which has been noticeably absent and will lead to greater market participation in a field that will continue to grow as automation boxes out other fields. Targeting areas that lead to innovation and businesses can allocate resources will put people to work.Please do not misinterpret me to suggest that we need more education. I’d wager there are less than 1,000 people in America using an art history degree for its intended purpose. Instead, this is a proposal to reallocate resources to target types of education where humans will be valuable – trades that machines have difficulty replacing and STEM fields where humans create the machines who replace them.My second proposal is to unburden small businesses. Legislators should be in the business of making it easier for small businesses to operate and comply with government regulation. If state and federal regulation is reduced, small businesses will be best situated to create jobs cheaply. Healthcare constantly being in flux, taxation changes, and legal hurdles make running a small business and creating jobs difficult and in an economy that many predict will desperately need to create employment, government doesn’t need to be a formidable burden in that process.My proposals are not perfect. There are plenty of holes in these proposals and many require intensive policy debates. The debates are worth having because a universal basis income is a road towards a dying economy – settling on a universal basic income is both lazy and simplistic. Without real ingenuity in the way we approach our workforce, we may be doomed to an economy bereft of innovation and liberty.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.027132983596283761,\n",
       "  'Amazon is a big player in that small space, but Whole Foods is small within it, and there are plenty of other would-be players.Moreover, Amazon will tell a seemingly plausible story to regulators and courts—that it only means to buy a troubled firm in need of a boost and only to support its entry in a space that it could not successfully enter on its own.'),\n",
       " (0.025796669950298744,\n",
       "  'But hopefully we also will see that a firm like Amazon embodies some things that are wrong with the policy and that it calls for action.That action could actually be taken in the Whole Foods case, and it is not even impossible that the Trump administration might take it.'),\n",
       " (0.023999653562320596,\n",
       "  'And the significance of it could not be overstated, not only because of Amazon’s own size and danger but for the broader revitalization it would bring to this crucial policy.'),\n",
       " (0.022704851496836192,\n",
       "  'The claim would be that this new acquisition and a series of prior acquisitions and other actions have delivered a market position in which Amazon is such a powerful buyer that it can force its suppliers to sell at subcompetitive prices.'),\n",
       " (0.022372377918973081,\n",
       "  'That is to say that it’s done just the thing that antitrust law says firms are supposed to do: It has competed on price and quality.'),\n",
       " (0.022334336904681885,\n",
       "  'A variety of the latter are well-documented, as, for example, Amazon’s use of its Amazon Marketplace platform to gather analytics on its Marketplace partners, then to enter their markets while using its data advantage and crushing terms to overtake the space.While President Trump’s antitrust leadership is not yet in place, his team appears most likely to consist of well-seasoned lawyer’s lawyers with sterling credentials in antitrust (specifically, Makan Delrahim and, as it is rumored, Joseph Simons).'),\n",
       " (0.021783360485077875,\n",
       "  'While it was hardly the first step in the firm’s competitive evolution, Friday’s breathtaking news that the e-commerce giant will acquire Whole Foods brings into sharp focus one of the deepest tensions in our antitrust law as it has evolved under 40 years of conservative orthodoxy.'),\n",
       " (0.021172061877940507,\n",
       "  ')First is the argument that Amazon will acquire Whole Foods mainly to kill off an online grocery rival—not now but in the future.'),\n",
       " (0.021082741489688164,\n",
       "  'To prove the claim, the government could first show that Amazon has very large shares of sales in specific products and that those shares reflect actual market power because Amazon has acquired truly, historically unique economies of scope that no retail entrant could meaningfully challenge.'),\n",
       " (0.021033297694143787,\n",
       "  'While Whole Foods is by no means the largest American grocer, and the deal’s $14 billion purchase price is not the biggest by any stretch, Whole Foods is among the larger chains in an industry worth upward of a trillion dollars per year.'),\n",
       " (0.020983587570562925,\n",
       "  'Though many Amazon critics fear it calls for some new, reconceptualized antitrust law, it actually seems nicely telling that existing law could deal with the Whole Foods acquisition and with Amazon’s behavior more generally, so long as certain established theories are taken seriously.'),\n",
       " (0.020860504858974421,\n",
       "  'The law has therefore proven persistently uninterested in its conduct.While this new merger must undergo federal antitrust review, the Trump administration is unlikely to challenge it.'),\n",
       " (0.020273011842636034,\n",
       "  'Our antitrust law, as it has come to be, is poorly equipped to deal with a company like Amazon.'),\n",
       " (0.02012772644636503,\n",
       "  'That is because, given the state of the law and the attitude of our judiciary, making a case against this deal will seem very challenging indeed.'),\n",
       " (0.020111847359835296,\n",
       "  'The fear and resentment of the poisonous 2016 Democratic presidential primary was driven by nothing less.The better news is that debate over Whole Foods, which seems likely to be pretty lively, could be a bit of a watershed moment for our competition policy.'),\n",
       " (0.019911151551427607,\n",
       "  'And of course, unlike any of Amazon’s prior targets, Whole Foods is among the best-known names in American retail.But still, an antitrust challenge is quite unlikely.'),\n",
       " (0.019386446799892553,\n",
       "  'While online grocery is now small, the industry plainly expects it to grow, and while there are currently several would-be entrants, there are specific reasons to expect that this combination will make their futures very, very bleak.'),\n",
       " (0.01914704202932771,\n",
       "  ')To many critics, that antitrust is so helpless in the face of a firm so big, acquisitive, and devastating proves how badly it has failed.'),\n",
       " (0.018861765644475375,\n",
       "  'Amazon is now the most interesting and important problem in American antitrust law.'),\n",
       " (0.018840957250441426,\n",
       "  'Amazon has been trying to get a foothold in grocery for a decade, but its only real success has been in England, where it has partnered with the traditional grocer Morrisons.Meanwhile Whole Foods has been stuck in a yearslong doldrums and this year came under dire pressure from Wall Street.'),\n",
       " (0.018452035808295859,\n",
       "  'The government could then show that these shares were acquired not by healthy, price-competitive vigor (in which case they would not be illegal).'),\n",
       " (0.018311584744033667,\n",
       "  'The Whole Foods acquisition could change that, if for no better reason that it represents a new level of audacity.'),\n",
       " (0.018059082768591011,\n",
       "  'The new administration ought to take them seriously.Up until now, the mainstream antitrust establishment has been pretty quiet about Amazon, no doubt because its visible conduct fits awkwardly with current ideas of what should be illegal.'),\n",
       " (0.018010784869347086,\n",
       "  'The struggle is between the haughty pride of our establishment institutions and their apparent impotence against the power and greed from which they are supposed to protect us.'),\n",
       " (0.017695642580345089,\n",
       "  'There are a few theories of actionable anticompetitive harm, even on our existing law, by which the government could bring challenge.'),\n",
       " (0.017470460237097724,\n",
       "  'That they are also very conservative does not mean they won’t bring important cases, and this could be one.'),\n",
       " (0.017449789608543688,\n",
       "  'They will require digging more deeply than the superficial story that Amazon will tell in its own defense, but they won’t require any radical change to the law we’ve got.'),\n",
       " (0.017229825311521174,\n",
       "  'Ideally, recognition might emerge that antitrust as it has evolved, including even its general, simple focus on price competition and protection of consumers, is actually a reasonably tolerable policy.'),\n",
       " (0.017185837511328409,\n",
       "  'Though Amazon has acquired hundreds of other firms in the past, some big and many controversial, never before has it bought a significant brick-and-mortar operation.'),\n",
       " (0.017085951826656658,\n",
       "  'This argument would take the deal not so much as “horizontal” and so would begin at a disadvantage.'),\n",
       " (0.016935992960642913,\n",
       "  'Even if (as seems unlikely) a court found there to be a legally relevant market consisting only of online grocery sales, no serious challenge would be likely.'),\n",
       " (0.016876567034950989,\n",
       "  'Over the years, as its critics have raised increasingly urgent alarms and elaborated on the firm’s history of fairly nasty aggression, what’s angered them most have been Amazon’s tentative forays into terrestrial stores of its own.'),\n",
       " (0.016692883581581032,\n",
       "  'Then, just two months ago, a surprise incursion by an activist hedge fund bred immediate speculation that Whole Foods was on the auction block.And yet there is a better way to characterize this deal and at least two good angles for legal attack.'),\n",
       " (0.01660680005095495,\n",
       "  'Amazon has a history of such maneuvers, as in its notorious, bare-knuckled acquisitions of Zappos and Diapers.com, as well as dozens of smaller acquisitions of otherwise threatening startups.'),\n",
       " (0.01610645590884445,\n",
       "  'A range of its particular actions over a few decades potentially makes out a claim, even under our current antitrust law, of illegal monopolization (in technical terms, a claim under Section 2 of the Sherman Act, rather than a merger challenge under Section 7 of the Clayton Act).'),\n",
       " (0.016103702561587881,\n",
       "  'It generates good outcomes most of the time and could get better yet just with more vigorous enforcement and popular support.'),\n",
       " (0.015915921654757258,\n",
       "  'Amazon is enormous, and it is apparently rapacious and remorseless.'),\n",
       " (0.015663229185005227,\n",
       "  'Rather, they were gotten through a series of acquisitions that may not have been individually illegal but in combination were monopolistic and by other exclusionary acts.'),\n",
       " (0.015542769449753337,\n",
       "  'While monopsony claims are rare and difficult to bring, Amazon is no ordinary antitrust defendant.'),\n",
       " (0.015187110265535915,\n",
       "  'But antitrust protects “dynamic” as well as static competition, and mergers are illegal where they will thwart technological or other developments that pose future competition.'),\n",
       " (0.015174324768151313,\n",
       "  'They seem to confirm a deliberately predatory, monopolizing strategy: Amazon kills off brick-and-mortar retail competition through desperation prices, only to take over those rivals’ physical presence as soon as they are gone.'),\n",
       " (0.015170899399394158,\n",
       "  'Nowadays, the federal antitrust agencies almost never challenge mergers unless they are “horizontal”—between head-to-head competitors—and they cause very high levels of concentration.'),\n",
       " (0.015015224740393143,\n",
       "  'The firms’ only overlapping business is online grocery, which so far remains a vanishingly small share of overall grocery.'),\n",
       " (0.015001587503884964,\n",
       "  'But at least superficially, it has done nothing in its 20-year life but sell things more cheaply and innovatively than its competitors.'),\n",
       " (0.0147701662540338,\n",
       "  'Vigorous challenge from mainstream chains and superstores led to a loss of nearly half the firm’s share value over just a few years.'),\n",
       " (0.014635159139199426,\n",
       "  'When the acquiring firm’s stock goes up, instead, investors must expect something profitable, and it’s very unlikely they’re just buying the sing-song synergy promises that every CEO makes for every deal.'),\n",
       " (0.014613701125459455,\n",
       "  '(Such an approach is also much more politically plausible right now than any holistic, revolutionary change in the underlying law.'),\n",
       " (0.014570251699530763,\n",
       "  'This new deal is also a big one in absolute dollars.'),\n",
       " (0.014524742454145617,\n",
       "  '(And while it’s not in itself legally relevant, markets have already indicated their confidence in some such anticompetitive outcome.'),\n",
       " (0.013768272443417164,\n",
       "  '(Disclosure: Slate is an Amazon affiliate; when you click on an Amazon link from Slate, the magazine gets a cut of the proceeds from whatever you buy.'),\n",
       " (0.013758170632593204,\n",
       "  'Wall Street so cynically discounts the motives of executives setting up mergers—something like 70 percent of which fail—that acquiring firms’ shares usually fall when deals are announced.'),\n",
       " (0.012535716671395577, 'This merger is only barely horizontal.'),\n",
       " (0.012464306010590382,\n",
       "  'Its failure, then, reflects an even larger tension, especially on the American left.'),\n",
       " (0.012320949162238916,\n",
       "  ')Better yet, a second theory would challenge Amazon’s conduct overall.'),\n",
       " (0.01230236990438097,\n",
       "  'That likely doesn’t reflect investor expectation of efficiency-enhancing integration, because no investors really believe in such things.'),\n",
       " (0.011675000595427186,\n",
       "  'The Obama administration probably wouldn’t have either, and neither would a Clinton administration.'),\n",
       " (0.011200353246206761,\n",
       "  'On Friday’s announcement, Amazon’s share price rose.')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textrank(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
